# German Insurance AI Agent Backend

A backend API service for an intelligent insurance assistant that uses Retrieval-Augmented Generation (RAG) to answer questions about German insurance products and policies.

## ğŸ¯ Project Purpose

This backend powers an AI-driven insurance assistant that:
- Answers customer questions about insurance products
- Retrieves relevant information from a vector database
- Provides accurate, context-aware responses using LLM technology
- Handles queries about German insurance companies and their offerings

## ğŸ› ï¸ Tech Stack

- **Runtime**: Node.js with ES Modules
- **Framework**: Express.js
- **Database**: Supabase with pgvector extension
- **AI/ML**: Google Vertex AI (Embeddings + LLM)
- **Architecture**: RAG (Retrieval-Augmented Generation)

## ğŸ“¡ API Endpoints

### Health Check
```
GET /api/health
```
Returns server health status.

**Response:**
```json
{
  "status": "ok"
}
```

### Query Insurance Information
```
POST /api/query
```
Submit a question about insurance products.

**Request Body:**
```json
{
  "question": "What types of health insurance are available in Germany?"
}
```

**Response:**
```json
{
  "question": "What types of health insurance are available in Germany?",
  "answer": "AI-generated answer based on retrieved context",
  "sources": []
}
```

## ğŸ“ Project Structure

```
german_insurance_backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.js                    # Express server entry point
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ index.js                # Main router
â”‚   â”‚   â”œâ”€â”€ query.routes.js         # Query endpoint routes
â”‚   â”‚   â””â”€â”€ insurers.routes.js      # Insurer management routes
â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”œâ”€â”€ query.controller.js     # Handles query requests
â”‚   â”‚   â””â”€â”€ insurers.controller.js  # Handles insurer operations
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ rag.service.js          # RAG pipeline orchestration
â”‚   â”‚   â”œâ”€â”€ embedding.service.js    # Text embedding generation
â”‚   â”‚   â””â”€â”€ llm.service.js          # LLM interaction
â”‚   â”œâ”€â”€ middleware/                 # Express middleware
â”‚   â”‚   â”œâ”€â”€ errorHandler.js         # Global error handling
â”‚   â”‚   â”œâ”€â”€ validation.js           # Request validation
â”‚   â”‚   â””â”€â”€ requestLogger.js        # Request logging
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â””â”€â”€ supabase.js             # Supabase client configuration
â”‚   â””â”€â”€ utils/                      # Utility functions
â”‚       â”œâ”€â”€ retry.js                # Retry with backoff
â”‚       â””â”€â”€ timeout.js              # Timeout utilities
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ schema.sql                  # Database schema
â”‚   â”œâ”€â”€ verify-pgvector.sql         # pgvector verification
â”‚   â””â”€â”€ migrations/                 # Migration scripts
â”‚       â”œâ”€â”€ 001_initial_schema.sql
â”‚       â”œâ”€â”€ rollback_001_initial_schema.sql
â”‚       â””â”€â”€ 002_sample_data.sql
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ test-pipeline.js            # Test data processing pipeline
â”‚   â””â”€â”€ data-processing/            # Data ingestion pipeline
â”‚       â”œâ”€â”€ README.md               # Processing guide
â”‚       â”œâ”€â”€ 01-clean-documents.js   # Text cleaning
â”‚       â”œâ”€â”€ 02-chunk-documents.js   # Document chunking
â”‚       â”œâ”€â”€ 03-generate-embeddings.js # Embedding generation
â”‚       â”œâ”€â”€ 04-upload-to-supabase.js  # Database upload
â”‚       â”œâ”€â”€ utils/                  # Processing utilities
â”‚       â”‚   â”œâ”€â”€ text-cleaner.js     # Text cleaning functions
â”‚       â”‚   â”œâ”€â”€ chunker.js          # Chunking algorithms
â”‚       â”‚   â””â”€â”€ progress-tracker.js # Progress tracking
â”‚       â””â”€â”€ logs/                   # Processing logs
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                        # Raw insurance documents
â”‚   â”‚   â”œâ”€â”€ *.txt                   # Sample documents
â”‚   â”‚   â””â”€â”€ metadata.json           # Document metadata
â”‚   â””â”€â”€ processed/                  # Processed data
â”‚       â”œâ”€â”€ clean/                  # Cleaned documents
â”‚       â”œâ”€â”€ chunks/                 # Document chunks
â”‚       â””â”€â”€ embeddings/             # Chunks with embeddings
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md             # System architecture
â”‚   â”œâ”€â”€ data-flow.md                # Data flow diagrams
â”‚   â”œâ”€â”€ day1-architecture.md        # Architecture & conventions
â”‚   â”œâ”€â”€ day2-schema-design.md       # Database schema design
â”‚   â”œâ”€â”€ day3-patterns.md            # Express patterns guide
â”‚   â”œâ”€â”€ day4-rag-diagrams.md        # RAG pipeline diagrams
â”‚   â”œâ”€â”€ day9-schema-finalization.md # Schema finalization & migrations
â”‚   â””â”€â”€ supabase-setup.md           # Database setup guide
â”œâ”€â”€ test-connection.js              # Database connection test
â”œâ”€â”€ test-query.js                   # API query test
â”œâ”€â”€ .env.example                    # Environment template
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

## ğŸ—ï¸ Architecture

This project follows a **layered architecture** with clear separation of concerns:

### Route â†’ Controller â†’ Service â†’ Database Pattern

```
HTTP Request
     â†“
[Route + Middleware]    â† Define endpoints, attach validation
     â†“
[Controller]            â† Handle HTTP (req/res)
     â†“
[Service Layer]         â† Business logic & orchestration
     â†“
[Database/APIs]         â† Data access (Supabase, Vertex AI)
     â†“
HTTP Response
```

**Key Principles**:
- **Routes**: Define HTTP endpoints and middleware
- **Controllers**: Handle request/response, delegate to services
- **Services**: Contain business logic, call external APIs
- **Middleware**: Cross-cutting concerns (logging, errors, validation)
- **Utils**: Reusable helper functions

For detailed architecture documentation, see [`docs/day1-architecture.md`](docs/day1-architecture.md)

## ğŸ”„ RAG Pipeline Explanation

The Retrieval-Augmented Generation pipeline works in four steps:

1. **Embedding Generation**: User questions are converted into vector embeddings using Vertex AI's embedding model
2. **Semantic Search**: The embedding is used to query Supabase/pgvector for the most relevant insurance document chunks
3. **Context Building**: Retrieved chunks are formatted into a prompt with the original question
4. **LLM Response**: The prompt is sent to Vertex AI's LLM, which generates a contextually accurate answer

This approach ensures responses are grounded in actual insurance documentation rather than relying solely on the LLM's training data.

**ğŸ“Š For detailed visual diagrams and flow documentation, see:**
- [`docs/day4-rag-diagrams.md`](docs/day4-rag-diagrams.md) - Complete RAG pipeline diagrams
- [`docs/data-flow.md`](docs/data-flow.md) - Detailed data flow visualization
- [`docs/architecture.md`](docs/architecture.md) - System architecture overview

## ğŸš€ Getting Started

### Prerequisites
- Node.js (v18 or higher)
- Supabase account with pgvector enabled
- Google Cloud account with Vertex AI access

### Installation

1. Clone the repository
```bash
cd german_insurance_backend
```

2. Install dependencies
```bash
npm install
```

3. Configure environment variables

Create a `.env` file in the root directory:
```env
PORT=3000
SUPABASE_URL=your_supabase_project_url
SUPABASE_SERVICE_KEY=your_supabase_service_key
```

4. Start the server

Development mode (with auto-reload):
```bash
npm run dev
```

Production mode:
```bash
npm start
```

The server will start on `http://localhost:3000`

## ğŸ“¦ Data Processing Pipeline

### Process Sample Documents

Test the complete data ingestion pipeline:

```bash
# Run complete test with sample data
node scripts/test-pipeline.js

# Or run individual steps
npm run process:clean    # Clean raw documents
npm run process:chunk    # Chunk cleaned documents
npm run process:embed    # Generate embeddings
npm run process:upload   # Upload to Supabase
```

### Process Your Own Documents

1. **Add your documents** to `data/raw/` directory
2. **Update metadata** in `data/raw/metadata.json`
3. **Run the pipeline**:
```bash
npm run process:all
```

See `scripts/data-processing/README.md` for detailed documentation.

## ğŸ§ª Testing the API

Test the health endpoint:
```bash
curl http://localhost:3000/api/health
```

Test database connection:
```bash
npm test
# or
node test-connection.js
```

Test a query:
```bash
curl -X POST http://localhost:3000/api/query \
  -H "Content-Type: application/json" \
  -d '{"question": "What is private health insurance?"}'
```

## ğŸ“ Development Status

### Completed
- âœ… **Task 1-7**: Express server, routes, controllers, services, middleware
- âœ… **Task 8 (Day 2)**: Database schema design (3 tables, pgvector)
- âœ… **Task 9 (Day 9)**: Schema finalization & migrations (20+ indexes, 4 functions)
- âœ… **Task 10 (Day 10)**: Project organization & team coordination
- âœ… **Task 11 (Day 11)**: Git repository & configuration (.gitignore, package.json)
- âœ… **Task 12 (Day 12)**: Supabase setup & backend connection
- âœ… **Task 13 (Day 13)**: Data ingestion pipeline (4 scripts, 3 utilities, tested)

### In Progress
- ğŸ”„ **Task 14**: Vertex AI embedding integration (production)
- ğŸ”„ **Task 15**: RAG pipeline implementation & end-to-end testing

### Planned
- ğŸ“‹ **Task 16+**: Production deployment, monitoring, optimization

## ğŸ“š Documentation

### Core Documentation
- **Architecture**: [`docs/day1-architecture.md`](docs/day1-architecture.md) - Complete architecture guide
- **Database Schema**: [`docs/day2-schema-design.md`](docs/day2-schema-design.md) - Table designs & pgvector
- **Express Patterns**: [`docs/day3-patterns.md`](docs/day3-patterns.md) - Middleware & async patterns
- **RAG Pipeline**: [`docs/day4-rag-diagrams.md`](docs/day4-rag-diagrams.md) - Visual diagrams & data flow

### Implementation Guides
- **Schema Finalization**: [`docs/day9-schema-finalization.md`](docs/day9-schema-finalization.md) - Migration scripts & deployment
- **Supabase Setup**: [`docs/supabase-setup.md`](docs/supabase-setup.md) - Database configuration & connection
- **Team Coordination**: [`docs/coordination-guide.md`](docs/coordination-guide.md) - Workflow & responsibilities

### Evidence Guides
- **Day 2 Evidence**: [`docs/day2-evidence-guide.md`](docs/day2-evidence-guide.md) - Schema design verification
- **Day 9 Evidence**: [`docs/day9-evidence-guide.md`](docs/day9-evidence-guide.md) - Migration deployment
- **Day 10 Evidence**: [`docs/task10-evidence-guide.md`](docs/task10-evidence-guide.md) - Project organization
- **Day 12 Evidence**: [`docs/task12-evidence-guide.md`](docs/task12-evidence-guide.md) - Supabase setup verification

## ğŸ¤ Contributing

This is a backend service for the German Insurance AI Agent project. For questions or contributions, please refer to the main project documentation.
